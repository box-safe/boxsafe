{
  "ai": {
    "source": "cloud",

    "local": {
      "enabled": false,
      "endpoint": "http://127.0.0.1:8080",
      "model": "Llama.gguf",
      "parameters": {},
      "limits": {
        "requests": "infinity"
      }
    },

    "cloud": {
      "provider": "google",
      "model": "gemini-2.5-flash",
      "limits": {
        "requests": 10,
        "tokens": "infinity"
      },
      "modelRotation": {
        "enabled": false,
        "extras": [],
        "maxMain": 10,
        "maxExtras": "infinity"
      }
    }
  },

  "sandbox": {
    "enabled": false,
    "engine": "docker",
    "container": {
      "root": true,
      "memory": "256m",
      "cpu": 0.3,
      "network": "none",
      "runtime": "default",
      "restart": "no"
    }
  },

  "commands": {
    "run": ["executable", ["npm", "run", "dev"]],
    "setup": ["npm", "init", "-y"]
  },

  "paths": {
    "root": "@",
    "write": "@"
  }
}
