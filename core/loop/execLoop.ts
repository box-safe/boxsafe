/**
 * @fileoverview
 * Implements an iterative agent loop that coordinates LLM code generation,
 * execution, and validation until a successful result is achieved.
 *
 * @description
 * The loop follows a deterministic pipeline:
 * 1. Send feedback to an LLM instance.
 * 2. Read the generated markdown artifact.
 * 3. Extract language-specific code blocks.
 * 4. Write the extracted code to an output file.
 * 5. Execute the output via a system command.
 * 6. Validate execution results using a waterfall validator.
 * 7. Generate structured feedback on failure and retry.
 *
 * The process repeats until validation succeeds.
 *
 * This module is designed for automated agent workflows.
 * Logs and artifacts are intended for machine consumption, not humans.
 *
 * @module core/loop
 */

import { readFile } from "node:fs/promises";
import { pathToCode } from "@core/paths/paths";
import { createLLM } from "@ai/provider";
import { runLLM } from "@ai/caller";
import { LService, LModel } from "@ai/label";
import { extractCode } from "@/util/extractCode";
import type { CommandRun } from "@/types";
import { execode } from "@core/cmd/execode";
import { ANSI } from "@util/ANSI";
import { createNavigator } from "@core/navigate";
import type { Navigator } from "@core/navigate";
import TasksManager from './tasks';
import { loadBoxConfig, getVersionControlFlags } from './boxConfig';
import { createVersionControlAttemptRunner } from './versionControlAdapter';
import { dispatchToolCalls } from './toolDispatcher';
import { initTasksManager } from './initTasksManager';
import { initNavigator } from './initNavigator';
import { writeArtifactAtomically } from './writeArtifactAtomically';
import { buildExecCommand } from './buildExecCommand';
import { runValidation } from './runValidation';
import type { LoopOptions, LoopResult } from './types';

/**
 * Create a navigator instance with the given workspace.
 * Useful for creating navigator before loop or injecting custom config.
 * @param workspace - path to workspace directory
 * @param maxFileSize - optional maximum file size in bytes (default 10MB)
 * @returns Navigator instance
 */
export const createWorkspaceNavigator = (workspace: string, maxFileSize?: number): Navigator => {
  return createNavigator({
    workspace,
    maxFileSize: maxFileSize ?? 10 * 1024 * 1024, // maximum in bytes
  });
}; // Summary: Get the working path, adjust it to absolute, and get the maximum size in MB for a file.

// Reads the markdown file generated by the model (path injectable for testability)
const readMarkdown = async (markdownPath: string) => {
  return readFile(markdownPath, "utf-8");
};

export const loop = async (
  {
    service,
    model,
    initialPrompt,
    cmd,
    lang,
    pathOutput,
    maxIterations = 10,
    limit,
    signal,
    pathGeneratedMarkdown = pathToCode,
    navigator: injectedNavigator,
    workspace,
    logger,
  } : LoopOptions
): Promise<LoopResult> => {
  const llm = createLLM(service, model);
  const log = logger ?? console;

  // Version control: configurable commit messages and behavior
  // Top-level variable for the 'before' commit message so it's easy to find and change.
  const BEFORE_COMMIT_MESSAGE = process.env.BOXSAFE_BEFORE_MSG ?? 'save agent';

  const boxConfig = loadBoxConfig();
  const { vcBefore, vcAfter, vcGenerateNotes, vcAutoPushConfig } = getVersionControlFlags(boxConfig);
  const attemptVersionControl = createVersionControlAttemptRunner(log, ANSI);

  // If configured, run a one-time 'before' commit when the agent starts
  if (vcBefore) {
    try {
      const res = await attemptVersionControl({ repoPath: workspace ?? process.cwd(), commitMessage: BEFORE_COMMIT_MESSAGE, autoPush: vcAutoPushConfig, generateNotes: vcGenerateNotes });
      log.info(`${ANSI.Cyan}[VersionControl]${ANSI.Reset} before-commit completed: ${JSON.stringify(res)}`);
    } catch (err: any) {
      log.warn(`${ANSI.Yellow}[VersionControl]${ANSI.Reset} before-commit failed after retries: ${err?.message ?? err}`);
    }
  }

  const tasksManager: TasksManager | null = await initTasksManager(boxConfig, log, ANSI);

  // Determine effective workspace (from arg, config or cwd) and initialize navigator
  const { effectiveWorkspace, navigator } = initNavigator({
    ...(workspace ? { workspaceArg: workspace } : {}),
    ...(boxConfig.project?.workspace ? { configWorkspace: boxConfig.project.workspace } : {}),
    ...(injectedNavigator ? { injectedNavigator } : {}),
  });

  const effectiveLimit = typeof limit === "number" ? limit : maxIterations;
  // feedback starts from tasks manager current task if available, otherwise initial prompt
  let feedback = initialPrompt;
  if (tasksManager && !tasksManager.isFinished()) {
    const t = tasksManager.getCurrentTask();
    if (t) feedback = t;
  }

  const sleep = (ms: number) => new Promise((r) => setTimeout(r, ms));

  for (limit = 1; limit <= effectiveLimit; limit++) {
    if (signal?.aborted) {
      log.error(`${ANSI.Red}[Agent]${ANSI.Reset} aborted`);
      return { ok: false, iterations: limit, navigator };
    }

    log.info(`${ANSI.Cyan}[Agent]${ANSI.Reset} iteration ${limit}`);

    // Run the LLM with the current feedback (with a small retry/backoff for transient LLM errors)
    let llmAttempts = 0;
    const maxLlmAttempts = 3;
    while (true) {
      try {
        if (signal?.aborted) throw new Error("Aborted");
        // Ensure the model (or mock) receives an explicit instruction about
        // the requested code language so we consistently get the correct
        // fenced block back. This helps the mock and real LLMs produce the
        // expected language output regardless of previous feedback text.
        const promptToSend = `${feedback}\n\nRespond ONLY with a single code block in the language: ${lang}`;
        await runLLM(promptToSend, llm);
        break;
      } catch (err: any) {
        llmAttempts++;
        log.error(`${ANSI.Red}[LLM Runner]${ANSI.Reset}`, err?.message ?? err);
        if (llmAttempts >= maxLlmAttempts) {
          return { ok: false, iterations: limit, navigator };
        }
        const backoff = 200 * Math.pow(2, llmAttempts - 1);
        await sleep(backoff);
      }
    }

    // Read the generated markdown
    let markdown: string;
    try {
      if (signal?.aborted) throw new Error("Aborted");
      markdown = await readMarkdown(pathGeneratedMarkdown);
    } catch (err: any) {
      log.error(`${ANSI.Red}[ReadMarkdown]${ANSI.Reset}`, err?.message ?? err);
      // give feedback to the model and retry
      feedback = "Could not read the generated markdown. Please emit markdown artifact.";
      continue;
    }

    // Extract code blocks for the target language
    let codeBlocks: string[];
    try {
      if (signal?.aborted) throw new Error("Aborted");
      codeBlocks = await extractCode(markdown, lang, {
        throwOnNotFound: true,
      });
    } catch (err: any) {
      log.warn(`${ANSI.Yellow}[ExtractCode]${ANSI.Reset}`, err?.message ?? err);
      feedback = "No code blocks were found. Generate valid code for the requested language.";
      continue;
    }

    // --- Tool call handling: detect JSON tool blocks in the generated markdown ---
    await dispatchToolCalls({
      markdown,
      navigator,
      boxConfig,
      log,
      ANSI,
      attemptVersionControl,
      vcAutoPushConfig,
    });

    if (!codeBlocks || codeBlocks.length === 0) {
      feedback = "No code blocks were found. Generate valid code.";
      continue;
    }

    // Atomic write: write to temp and rename
    const tmpPath = `${pathOutput}.tmp`;
    try {
      await writeArtifactAtomically({
        tmpPath,
        pathOutput,
        content: codeBlocks.join("\n\n"),
        ...(signal ? { signal } : {}),
      });
    } catch (err: any) {
      log.error(`${ANSI.Red}[WriteFile]${ANSI.Reset}`, err?.message ?? err);
      feedback = "Failed to write output file. Ensure filesystem permissions are correct.";
      continue;
    }

    // Execute the generated code
    let execResult: any;
    try {
      if (signal?.aborted) throw new Error("Aborted");
      const execCmd = await buildExecCommand({ cmd, lang, pathOutput, log, ANSI });
      execResult = await execode(execCmd);
    } catch (err: any) {
      log.error(`${ANSI.Red}[Execode]${ANSI.Reset}`, err?.message ?? err);
      feedback = `Execution failed: ${err?.message ?? "unknown"}`;
      continue;
    }

    // Debug: log exec output and the written artifact to diagnose failures
    try {
      log.info(`${ANSI.Cyan}[Execode]${ANSI.Reset} exit=${execResult.exitCode}`);
      log.info(`${ANSI.Cyan}[Execode]${ANSI.Reset} stdout=${String(execResult.stdout).slice(0,1000)}`);
      log.info(`${ANSI.Cyan}[Execode]${ANSI.Reset} stderr=${String(execResult.stderr).slice(0,1000)}`);
      try {
        const outFile = await readFile(pathOutput, 'utf-8');
        log.info(`${ANSI.Cyan}[OutputFile]${ANSI.Reset} ${outFile.slice(0,1000)}`);
      } catch (err: any) {
        log.info(`${ANSI.Cyan}[OutputFile]${ANSI.Reset} could not read output file: ${err?.message ?? err}`);
      }
    } catch (errAny) {
      // swallow logging errors
    }

    // Validate execution results using the waterfall pipeline
    let verdict: any;
    try {
      verdict = await runValidation({
        execResult,
        pathOutput,
        ...(signal ? { signal } : {}),
        log,
        ANSI,
      });
    } catch (err: any) {
      feedback = `Validation pipeline failed: ${err?.message ?? "unknown"}`;
      continue;
    }

    // Stop or advance if the execution is valid
    if (verdict?.ok) {
      log.info(`${ANSI.Green}[Agent]${ANSI.Reset} success for current task/iteration`);

      // If task manager is active, mark current done and continue to next
      if (tasksManager) {
        await tasksManager.markCurrentDone();
        if (!tasksManager.isFinished()) {
          const next = tasksManager.getCurrentTask();
          feedback = next ?? feedback;
          log.info(`${ANSI.Cyan}[Tasks]${ANSI.Reset} advanced to next task`);
          // continue loop to process next task
          continue;
        }
        // all tasks done â€” proceed to after-success flow below
        log.info(`${ANSI.Cyan}[Tasks]${ANSI.Reset} all tasks completed`);
      }

      // After-success versioning (commit explaining what was done)
      if (vcAfter) {
        const afterMessage = `agent: completed successfully in ${limit} iterations`;
        try {
          const res = await attemptVersionControl({ repoPath: workspace ?? process.cwd(), commitMessage: afterMessage, autoPush: vcAutoPushConfig, generateNotes: vcGenerateNotes });
          log.info(`${ANSI.Cyan}[VersionControl]${ANSI.Reset} after-commit completed: ${JSON.stringify(res)}`);
        } catch (err: any) {
          log.warn(`${ANSI.Yellow}[VersionControl]${ANSI.Reset} after-commit failed after retries: ${err?.message ?? err}`);
        }
      }

      return { ok: true, iterations: limit, verdict, artifacts: { outputFile: pathOutput }, navigator };
    }

    // Build structured feedback for the next iteration
    feedback = `Layer: ${verdict?.layer ?? "unknown"}\nReason: ${verdict?.reason ?? "unknown"}\nDetails: ${verdict?.details ?? "n/a"}`;

    log.warn(`${ANSI.Yellow}[Waterfall]${ANSI.Reset} failed at ${verdict?.layer ?? "unknown"}`);
  }

  // If the loop completes without a successful verdict
  return { ok: false, iterations: limit, navigator };
};
