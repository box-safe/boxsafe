/**
 * @fileoverview
 * Implements an iterative agent loop that coordinates LLM code generation,
 * execution, and validation until a successful result is achieved.
 *
 * @description
 * The loop follows a deterministic pipeline:
 * 1. Send feedback to an LLM instance.
 * 2. Read the generated markdown artifact.
 * 3. Extract language-specific code blocks.
 * 4. Write the extracted code to an output file.
 * 5. Execute the output via a system command.
 * 6. Validate execution results using a waterfall validator.
 * 7. Generate structured feedback on failure and retry.
 *
 * The process repeats until validation succeeds.
 *
 * This module is designed for automated agent workflows.
 * Logs and artifacts are intended for machine consumption, not humans.
 *
 * @module core/loop
 */

import { readFile } from "node:fs/promises";
import { pathToCode } from "@core/paths/paths";
import { createLLM } from "@ai/provider";
import { runLLM } from "@ai/caller";
import { LService, LModel } from "@ai/label";
import { extractCode } from "../../util/extractCode";
import type { CommandRun } from "../../types";
import { execode } from "./cmd/execode";
import { ANSI } from "@util/ANSI";
import { createNavigator } from "@core/navigate";
import type { Navigator } from "@core/navigate";
import TasksManager from '@core/loop/tasks';
import { loadBoxConfig, getVersionControlFlags } from '@core/loop/boxConfig';
import { createVersionControlAttemptRunner } from '@core/loop/versionControlAdapter';
import { dispatchToolCalls } from '@core/loop/toolDispatcher';
import { initTasksManager } from '@core/loop/initTasksManager';
import { initNavigator } from '@core/loop/initNavigator';
import { writeArtifactAtomically } from '@core/loop/writeArtifactAtomically';
import { buildExecCommand } from '@core/loop/buildExecCommand';
import { runValidation } from '@core/loop/runValidation';
import type { LoopOptions, LoopResult } from '@core/loop/types';
import { createTraceLogger } from '@core/loop/traceLogger';

/**
 * Create a navigator instance with the given workspace.
 * Useful for creating navigator before loop or injecting custom config.
 * @param workspace - path to workspace directory
 * @param maxFileSize - optional maximum file size in bytes (default 10MB)
 * @returns Navigator instance
 */
export const createWorkspaceNavigator = (workspace: string, maxFileSize?: number): Navigator => {
  return createNavigator({
    workspace,
    maxFileSize: maxFileSize ?? 10 * 1024 * 1024, // maximum in bytes
  });
}; // Summary: Get the working path, adjust it to absolute, and get the maximum size in MB for a file.

// Reads the markdown file generated by the model (path injectable for testability)
const readMarkdown = async (markdownPath: string) => {
  return readFile(markdownPath, "utf-8");
};

export const loop = async (
  {
    service,
    model,
    initialPrompt,
    cmd,
    lang,
    pathOutput,
    maxIterations = 10,
    limit,
    signal,
    pathGeneratedMarkdown = pathToCode,
    navigator: injectedNavigator,
    workspace,
  } : LoopOptions
): Promise<LoopResult> => {
  const llm = createLLM(service, model);
  const trace = createTraceLogger({});
  const log = trace.wrapLogger();
  await trace.emit('loop.start', { runId: trace.runId }, {
    service: String(service),
    model: String(model),
    lang: String(lang),
    maxIterations: Number(maxIterations),
  });

  // Version control: configurable commit messages and behavior
  // Top-level variable for the 'before' commit message so it's easy to find and change.
  const BEFORE_COMMIT_MESSAGE = process.env.BOXSAFE_BEFORE_MSG ?? 'save agent';

  const boxConfig = loadBoxConfig();
  const { vcBefore, vcAfter, vcGenerateNotes, vcAutoPushConfig } = getVersionControlFlags(boxConfig);
  const attemptVersionControl = createVersionControlAttemptRunner();

  const configuredTimeoutMs = typeof boxConfig.commands?.timeoutMs === 'number' ? boxConfig.commands.timeoutMs : undefined;

  // If configured, run a one-time 'before' commit when the agent starts
  if (vcBefore) {
    try {
      await trace.emit('versionControl.before.start', { runId: trace.runId });
      const res = await attemptVersionControl({ repoPath: workspace ?? process.cwd(), commitMessage: BEFORE_COMMIT_MESSAGE, autoPush: vcAutoPushConfig, generateNotes: vcGenerateNotes });
      log.info(`${ANSI.Cyan}[VersionControl]${ANSI.Reset} before-commit completed: ${JSON.stringify(res)}`);
      await trace.emit('versionControl.before.ok', { runId: trace.runId }, { result: res as any });
    } catch (err: any) {
      log.warn(`${ANSI.Yellow}[VersionControl]${ANSI.Reset} before-commit failed after retries: ${err?.message ?? err}`);
      await trace.emit('versionControl.before.error', { runId: trace.runId }, { error: err?.message ?? String(err) });
    }
  }

  const tasksManager: TasksManager | null = await initTasksManager(boxConfig);

  // Determine effective workspace (from arg, config or cwd) and initialize navigator
  log.info(`${ANSI.Cyan}[InitNavigator]${ANSI.Reset} Initializing navigator...`);
  const { effectiveWorkspace, navigator } = initNavigator({
    ...(workspace ? { workspaceArg: workspace } : {}),
    ...(boxConfig.project?.workspace ? { configWorkspace: boxConfig.project.workspace } : {}),
    ...(injectedNavigator ? { injectedNavigator } : {}),
  });
  
  log.info(`${ANSI.Cyan}[InitNavigator]${ANSI.Reset} Navigator initialized: ${!!navigator ? 'YES' : 'NO'}, Workspace: ${effectiveWorkspace}`);

  const effectiveLimit = typeof limit === "number" ? limit : maxIterations;
  // feedback starts from tasks manager current task if available, otherwise initial prompt
  let feedback = initialPrompt;
  if (tasksManager && !tasksManager.isFinished()) {
    const t = tasksManager.getCurrentTask();
    if (t) feedback = t;
  }

  const sleep = (ms: number) => new Promise((r) => setTimeout(r, ms));

  for (limit = 1; limit <= effectiveLimit; limit++) {
    const iterCtx = { runId: trace.runId, iter: limit };
    const iterLog = trace.wrapLogger(iterCtx);
    if (signal?.aborted) {
      iterLog.error(`aborted`);
      await trace.emit('loop.aborted', iterCtx);
      return { ok: false, iterations: limit, navigator };
    }

    iterLog.info(`iteration ${limit}`);
    await trace.emit('iteration.start', iterCtx);

    // Run the LLM with the current feedback (with a small retry/backoff for transient LLM errors)
    let llmAttempts = 0;
    const maxLlmAttempts = 3;
    while (true) {
      try {
        if (signal?.aborted) throw new Error("Aborted");
        const promptToSend = `${feedback}\n\nYou may optionally emit tool calls as JSON fenced blocks (\`\`\`json-tool ...\`\`\`) BEFORE the final code block. If you do, set tool=\"navigate\" and params.op=\"write\" to create files. Then, ALWAYS end your response with exactly ONE code block in the language: ${lang}`;
        await trace.emit('llm.run.start', iterCtx);
        await runLLM(promptToSend, llm, { service, model, outputPath: pathGeneratedMarkdown });
        await trace.emit('llm.run.ok', iterCtx, { outputPath: pathGeneratedMarkdown });
        break;
      } catch (err: any) {
        llmAttempts++;
        iterLog.error(`${err?.message ?? err}`);
        await trace.emit('llm.run.error', iterCtx, { error: err?.message ?? String(err), attempt: llmAttempts });
        if (llmAttempts >= maxLlmAttempts) {
          await trace.emit('iteration.failed', iterCtx, { layer: 'llm' });
          return { ok: false, iterations: limit, navigator };
        }
        const backoff = 200 * Math.pow(2, llmAttempts - 1);
        await sleep(backoff);
      }
    }

    // Read the generated markdown
    let markdown: string;
    try {
      if (signal?.aborted) throw new Error("Aborted");
      markdown = await readMarkdown(pathGeneratedMarkdown);
      await trace.emit('markdown.read.ok', iterCtx, { path: pathGeneratedMarkdown, bytes: markdown.length });
    } catch (err: any) {
      iterLog.error(`${ANSI.Red}[ReadMarkdown]${ANSI.Reset} ${err?.message ?? err}`);
      await trace.emit('markdown.read.error', iterCtx, { error: err?.message ?? String(err), path: pathGeneratedMarkdown });
      // give feedback to the model and retry
      feedback = "Could not read the generated markdown. Please emit markdown artifact.";
      continue;
    }

    // Extract code blocks for the target language
    let codeBlocks: string[];
    try {
      if (signal?.aborted) throw new Error("Aborted");
      codeBlocks = await extractCode(markdown, lang, {
        throwOnNotFound: true,
      });
      await trace.emit('extractCode.ok', iterCtx, { blocks: codeBlocks.length, lang: String(lang) });
    } catch (err: any) {
      iterLog.warn(`${ANSI.Yellow}[ExtractCode]${ANSI.Reset} ${err?.message ?? err}`);
      await trace.emit('extractCode.error', iterCtx, { error: err?.message ?? String(err), lang: String(lang) });
      feedback = "No code blocks were found. Generate valid code for the requested language.";
      continue;
    }

    // --- Tool call handling: detect JSON tool blocks in the generated markdown ---
    iterLog.info(`${ANSI.Cyan}[ToolCalls]${ANSI.Reset} Processing tool calls from markdown...`);
    await dispatchToolCalls({
      markdown,
      navigator,
      boxConfig,
      ANSI,
      attemptVersionControl,
      vcAutoPushConfig,
      traceEmit: trace.emit.bind(trace),
      traceCtx: iterCtx,
    });
    iterLog.info(`${ANSI.Cyan}[ToolCalls]${ANSI.Reset} Tool call processing completed`);

    if (!codeBlocks || codeBlocks.length === 0) {
      feedback = "No code blocks were found. Generate valid code.";
      continue;
    }

    // Atomic write: write to temp and rename
    const tmpPath = `${pathOutput}.tmp`;
    try {
      await writeArtifactAtomically({
        tmpPath,
        pathOutput,
        content: codeBlocks.join("\n\n"),
        ...(signal ? { signal } : {}),
      });
      await trace.emit('artifact.write.ok', iterCtx, { path: pathOutput, bytes: codeBlocks.join("\n\n").length });
    } catch (err: any) {
      iterLog.error(`${ANSI.Red}[WriteFile]${ANSI.Reset} ${err?.message ?? err}`);
      await trace.emit('artifact.write.error', iterCtx, { error: err?.message ?? String(err), path: pathOutput });
      feedback = "Failed to write output file. Ensure filesystem permissions are correct.";
      continue;
    }

    // Execute the generated code
    let execResult: any;
    try {
      if (signal?.aborted) throw new Error("Aborted");
      const execCmd = await buildExecCommand({ cmd, lang, pathOutput });
      await trace.emit('exec.start', iterCtx, { cmd: Array.isArray(execCmd) ? execCmd[0] : execCmd });
      execResult = await execode(execCmd, {
        ...(configuredTimeoutMs !== undefined ? { timeoutMs: configuredTimeoutMs } : {}),
      });
      await trace.emit('exec.ok', iterCtx, { exitCode: execResult.exitCode });
    } catch (err: any) {
      iterLog.error(`${ANSI.Red}[Execode]${ANSI.Reset} ${err?.message ?? err}`);
      await trace.emit('exec.error', iterCtx, { error: err?.message ?? String(err) });
      feedback = `Execution failed: ${err?.message ?? "unknown"}`;
      continue;
    }

    // Debug: log exec output and the written artifact to diagnose failures
    try {
      iterLog.info(`${ANSI.Cyan}[Execode]${ANSI.Reset} exit=${execResult.exitCode}`);
      iterLog.info(`${ANSI.Cyan}[Execode]${ANSI.Reset} stdout=${String(execResult.stdout).slice(0,1000)}`);
      iterLog.info(`${ANSI.Cyan}[Execode]${ANSI.Reset} stderr=${String(execResult.stderr).slice(0,1000)}`);
      try {
        const outFile = await readFile(pathOutput, 'utf-8');
        iterLog.info(`${ANSI.Cyan}[OutputFile]${ANSI.Reset} ${outFile.slice(0,1000)}`);
      } catch (err: any) {
        iterLog.info(`${ANSI.Cyan}[OutputFile]${ANSI.Reset} could not read output file: ${err?.message ?? err}`);
      }
    } catch (errAny) {
      // swallow logging errors
    }

    // Validate execution results using the waterfall pipeline
    let verdict: any;
    try {
      await trace.emit('validation.start', iterCtx);
      verdict = await runValidation({
        execResult,
        pathOutput,
        ...(signal ? { signal } : {}),
      });
      await trace.emit('validation.ok', iterCtx, {
        ok: Boolean(verdict?.ok),
        score: typeof verdict?.score === 'number' ? verdict.score : undefined,
        layer: verdict?.layer ?? undefined,
      });
    } catch (err: any) {
      await trace.emit('validation.error', iterCtx, { error: err?.message ?? String(err) });
      feedback = `Validation pipeline failed: ${err?.message ?? "unknown"}`;
      continue;
    }

    // Stop or advance if the execution is valid
    if (verdict?.ok) {
      iterLog.info(`success for current task/iteration`);
      await trace.emit('iteration.success', iterCtx, {
        score: typeof verdict?.score === 'number' ? verdict.score : undefined,
      });

      // If task manager is active, mark current done and continue to next
      if (tasksManager) {
        await tasksManager.markCurrentDone();
        if (!tasksManager.isFinished()) {
          const next = tasksManager.getCurrentTask();
          feedback = next ?? feedback;
          log.info(`${ANSI.Cyan}[Tasks]${ANSI.Reset} advanced to next task`);
          // continue loop to process next task
          continue;
        }
        // all tasks done â€” proceed to after-success flow below
        log.info(`${ANSI.Cyan}[Tasks]${ANSI.Reset} all tasks completed`);
      }

      // After-success versioning (commit explaining what was done)
      if (vcAfter) {
        const afterMessage = `agent: completed successfully in ${limit} iterations`;
        try {
          await trace.emit('versionControl.after.start', iterCtx);
          const res = await attemptVersionControl({ repoPath: workspace ?? process.cwd(), commitMessage: afterMessage, autoPush: vcAutoPushConfig, generateNotes: vcGenerateNotes });
          log.info(`${ANSI.Cyan}[VersionControl]${ANSI.Reset} after-commit completed: ${JSON.stringify(res)}`);
          await trace.emit('versionControl.after.ok', iterCtx, { result: res as any });
        } catch (err: any) {
          log.warn(`${ANSI.Yellow}[VersionControl]${ANSI.Reset} after-commit failed after retries: ${err?.message ?? err}`);
          await trace.emit('versionControl.after.error', iterCtx, { error: err?.message ?? String(err) });
        }
      }

      return { ok: true, iterations: limit, verdict, artifacts: { outputFile: pathOutput }, navigator };
    }

    // Build structured feedback for the next iteration
    feedback = `Layer: ${verdict?.layer ?? "unknown"}\nReason: ${verdict?.reason ?? "unknown"}\nDetails: ${verdict?.details ?? "n/a"}`;

    iterLog.warn(`${ANSI.Yellow}[Waterfall]${ANSI.Reset} failed at ${verdict?.layer ?? "unknown"}`);
    await trace.emit('iteration.failed', iterCtx, {
      layer: verdict?.layer ?? 'unknown',
      reason: verdict?.reason ?? 'unknown',
      score: typeof verdict?.score === 'number' ? verdict.score : undefined,
    });
  }

  // If the loop completes without a successful verdict
  return { ok: false, iterations: limit, navigator };
};
